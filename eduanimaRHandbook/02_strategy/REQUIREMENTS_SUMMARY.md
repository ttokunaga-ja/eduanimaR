Title: Requirements & Answers Summary
Description: これまでの要求と、戦略レベルでの回答（決定事項/未決事項）を簡潔に整理
Owner: @OWNER
Reviewers: @reviewer1
Status: Draft
Last-updated: 2026-02-14
Tags: strategy, requirements

# Requirements & Answers Summary

## 1. 要求（整理）
### プロダクト形態
- Chrome拡張機能版を作成する
- Webアプリ版も作成する

### フロントエンド共通要件（UX/機能）
- UI/UX: 学習を妨げないクリーンなUI。透明性（参照元の提示）と即時性を重視
- Q&A: チャット形式UI。回答には参照元資料（ファイル/箇所）がクリッカブルに添付される
- 科目・ファイル管理: 科目ごとにツリー形式で保存ファイルを表示。Chrome拡張機能が自動アップロード時に科目を指定する（Web版にアップロードUIなし）
- 質問支援: ユーザーが曖昧な質問を入力した場合、LLMが具体的な選択肢を提示する。選択肢提示では資料検索を実施せず、LLMの推論のみで応答する。ユーザーが選択肢を選ぶと、元の曖昧な質問をコンテキストとして通常の検索フローへ移行する
- サポート: 質問履歴（スレッド保存）、不具合申告/お問い合わせフォームの常設

### 認証・アクセス制御
- 認証はSSO（OAuth/OIDC）を用いる
- 対応IdP（入口）: Google / Meta / Microsoft / LINE
- ユーザーごとのアクセス制限を厳格に実施する（資料・生成結果・ログの分離）

### 共有（将来想定）
- 初期は個人利用のみ
- 将来的に「科目の資料セット」のみ共有する可能性がある（科目ごとに資料内容が共通であり、整理・最適化目的）
- 質問履歴や重要箇所マーク等の個人の学習履歴は共有しない（プライバシー観点）

### データ/DB
- DBはFirestoreではなく、GCPのPostgreSQLを使用する
- AlloyDB AIは使用せず、PostgreSQL拡張のpgvectorを使用する
- Vision Reasoning等で資料から抜き出した内容を、検索に使うためDBに保存することは必須
- 事前OCR（テキスト化）はAgentの検索補助を目的に必須

### 検索/Agent
- Agentic Searchで資料を探索できるようにしたい
- 全文検索のみで行くべきか、EmbeddingされたドキュメントDBも必要か比較検討したい
- PostgreSQLのpgvector/ベクトル型を使うべきか検討したい
- MCPサーバの考え方を参考にすべきか検討したい

### 実装体制（責務）
- Agent開発はPython（LangGraph）
- 認証、イベント管理、キューイング用の受付コンテナはGo
- 前処理はGo + Kafkaで、OCR/Markdown化/Embedding化をキューイングする

### ロードマップ由来の要求
- Phase 4（小テストHTML解析）で扱う問題文・選択肢・正誤等の内容は「その場の解析のみ（保存しない/短期）」とする

## 2. 戦略レベルでの回答（結論）
### 技術的に可能か
- 事前OCR/抽出で「検索できるテキスト」を作り、検索→参照提示→要点/計画生成、という形での学習支援は技術的に実現可能
- 一方で、検索精度/遅延/コストは資料の形式と量、OCR品質、索引方式に依存するため、計測前提で進める

### RAG（検索+生成）との関係
- 学習支援の中心は、外部コーパス（自分の資料）から根拠を取り出す必要があるため、検索（全文/ベクトル）を含むRAG的構成は本質的
- 「RAGを採用するか否か」より、
  - どの索引（全文/ベクトル/ハイブリッド）を採用するか
  - どの粒度（ドキュメント/章/段落）で保存・参照するか
  - どのように権限制御をかけるか
  が成否を左右する

### 全文検索 vs Embedding DB（pgvector）
- 基本方針: 全文検索を基盤にして開始し、必要に応じてpgvectorでセマンティック検索を併用する
- 理由:
  - OCR後のテキストが整うほど全文検索の価値が高い
  - 同義語や抽象質問ではベクトルが効く
  - 「LLMが内蔵するベクトル能力」だけでは、外部資料を高速に引く索引にはならない

### pgvectorを使うべきか
- 使う価値は高い（PostgreSQL内でベクトル検索を扱えるため）
- ただし、初期は科目ID等で絞り込み+全文検索で十分な可能性がある
- データ量増加や要件（SLO/精度）に応じて、
  - 厳密検索→近似索引（HNSW/IVFFlat）
  - 全文+ベクトルのハイブリッド
  を段階的に導入する

### MCPサーバを参考にすべきか
- 「エージェントがツールを安全に呼ぶ」ための境界設計は参考にすべき
- 採用（プロトコル準拠）自体は、外部エコシステム連携の必要性を見て判断する

### Go/Pythonの責務（再確認）
- Go: 認証/認可境界、イベント/キュー、前処理（OCR/抽出/Embedding/DB反映）
- Python: LangGraphエージェント（検索ツールを使って探索し、根拠提示と学習支援の生成を行う）

## 3. 未決事項（要確認）
- （将来）学内IdP連携の必要性（Google Workspace / Azure AD / 学内IdP など）をいつ判断するか
- ユーザー分離の単位（初期: 個人のみ／将来: 科目の資料セットのみ共有、学習履歴は共有しない）
- 取り込む資料の主形式（PDF中心か、画像/HTML/スライド比率）
- 「科目ID」の付与方法（手動/自動、LMSから取得可否）
- 検索の最終的なSLO（許容レイテンシ）

（ロードマップ由来の確認事項）:
（なし）
