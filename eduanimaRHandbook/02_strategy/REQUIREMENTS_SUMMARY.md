Title: Requirements Summary
Description: eduanimaR 全体の機能要件・非機能要件のサマリ
Owner: @ttokunaga-ja
Reviewers: @reviewer1
Status: Published
Last-updated: 2026-02-18
Tags: strategy, requirements

# Requirements Summary

## プラットフォーム役割定義

### 共通機能（Web版・拡張機能版 共通）
- Q&Aチャット: 質問入力、AI Agent進捗プログレスバー表示、回答表示
- 根拠として使用した資料の確認（ファイル名・ページ・抜粋・クリッカブルURL）
- ヒアリング判断時の選択肢提示（曖昧な質問に対してLLMが候補を提示）
- 回答末尾の Good/Bad フィードバックボタン
- 認証（再ログイン等）
- お問い合わせ機能（Googleフォームリンク）

### Web版固有機能
- トップメニューバー中央の科目選択プルダウン（選択した科目がQ&A/資料/履歴の絞り込みに連動）
- 資料一覧: 選択科目のみ表示 or プルダウン「全て」で科目別グループ表示
- 会話履歴: 選択科目のみ表示 or プルダウン「全て」で科目別グループ表示
- 大画面レイアウトによる一覧閲覧

### Chrome拡張機能固有機能
- SSO経由のユーザー登録（Chrome拡張からのみ新規登録可）
- Moodle資料の自動検知・自動アップロード（MutationObserver）
- 現在閲覧中LMSコースの判別 → subject_id による物理検索制限（精度向上）
- Web版へのリンク

---

## Phase別機能要件

### Phase 1: バックエンド完全版 + Web版完全動作(2026 Q1)
**ゴール**: バックエンド機能の完全実装 + ローカルでのWeb版全機能動作確認

✅ **実装する機能（バックエンド）**:
- ファイルアップロード（PDF/画像）→ GCS保存 → Kafka非同期Ingest
- 自動OCR/Embedding生成（Kafka非同期パイプライン）
- 科目別資料管理（users/subjects/files/chunks テーブル）
- 質問応答（SSE: `/v1/subjects/{id}/chats`）
- Professor ↔ Librarian gRPC双方向ストリーミング（Phase 1から完全実装）
- ベクトル検索（pgvector 0.8.1 HNSW）
- 全文検索（PostgreSQL tsvector）
- 固定dev-user認証（`dev@example.com`、Phase 2でSSO置換）
- curlによる認証不要アップロード（ローカルテスト用）
- フィードバック保存（Good/Bad）
- 会話履歴保存・取得API

✅ **実装する機能（フロントエンド Web版）**:
- Q&Aチャット（SSEリアルタイム表示、プログレスバー）
- 根拠資料カード表示（クリッカブルURL）
- ヒアリング判断時の選択肢提示UI
- Good/Bad フィードバックボタン
- 科目選択プルダウン（メニューバー）
- 資料一覧（科目別フィルタ・全科目グループ表示）
- 会話履歴（科目別フィルタ・全科目グループ表示）
- お問い合わせリンク（Googleフォーム）
- dev-user自動ログイン（認証UIなし）

❌ **実装しない機能（Phase 2以降）**:
- SSO認証（Phase 2）
- Chrome拡張機能（Phase 2: ZIP配布、Phase 3: Web Store公開）

---

### Phase 2: Chrome拡張機能（ZIP配布）+ SSO認証(2026 Q2)
**ゴール**: Chrome拡張機能のZIPファイル配布 + SSO認証による本番運用開始

✅ **追加機能**:
- Chrome拡張機能（Plasmo / Manifest V3）→ ZIPファイルで配布
- SSO認証（Google/Meta/Microsoft/LINE）
- Moodle資料の自動検知・自動アップロード
- 現在閲覧LMSコース判別 → subject_id 物理制限
- Web版へのリンク（拡張機能から）
- Cloud Runデプロイ（Professor/Librarian）
- プライバシーポリシー/利用規約の法務確認

DB変更:
- `users`テーブルの`provider`, `provider_user_id`カラムをPhase 1から追加済み（NULLABLE）→ Phase 2で実際に使用
- 固定dev-user削除

---

### Phase 3: Chrome Web Store公開(2026 Q3)
**ゴール**: Chrome Web Storeでの正式公開

✅ **追加機能**:
- Chrome Web Store審査対応（プライバシーポリシー・スクリーンショット等）
- Chrome Web Store公開（非公開配布 → 公開配布へ移行）

---

### Phase 4: 閲覧画面解説機能(2026 Q4)
**ゴール**: 小テスト復習支援（間違った原因を資料をもとに考える支援）

✅ **追加機能**:
- 現在閲覧中LMS画面のHTML取得
- 画面内に表示されている画像ファイル取得（図・グラフ等）
- 取得したHTML・画像をProfessor APIへ送信→LLM解析
- 資料を根拠とした解説生成（「なぜ間違えたか」の支援）
- 短期保存（7日後自動削除、プライバシー配慮）

DB変更:
- `screen_analyses`テーブル追加

---

### Phase 5: 学習計画機能（構想段階）(2027 Q1~)
**ゴール**: 個別最適化された学習ロードマップ（構想段階・備考程度の位置づけ）

備考:
- 過去の小テスト結果を取得・分析し、既存資料のどこを確認すべきか・どの順序で学ぶべきかをチャット形式で提案する機能を想定
- 学習計画生成・匿名化処理等の詳細はPhase 1〜4完了後に検討する

---

## 非機能要件(全Phase共通)

### セキュリティ
- **認証**: Phase 1=固定dev-user、Phase 2以降=OAuth/OIDC
- **認可**: user_id/subject_idによる物理分離(DB層で強制)
- **監査**: request_idでログ/トレース相関
- **データ境界**: Professor独占(Librarian/フロントエンドはDB直接アクセス禁止)

### パフォーマンス
- ベクトル検索: < 1秒(pgvector HNSW)
- SSEストリーミング: 初回チャンク < 3秒
- ファイル処理: 非同期(Kafka)

### 可用性
- Cloud Run水平スケール
- Kafka DLQ(Dead Letter Queue)でリトライ制御

### 観測性
- OpenTelemetry(Phase 2以降)
- SLO/アラート(Phase 2以降)

---

## スコープ外(全Phase)
- 評価・採点の自動化
- 他者の資料への無断アクセス
- Web版からの新規ユーザー登録(拡張機能のみ)

---

## 1. 要求（整理）
### プロダクト形態
- Chrome拡張機能版を作成する
- Webアプリ版も作成する

### フロントエンド共通要件（UX/機能）
- UI/UX: 学習を妨げないクリーンなUI。透明性（参照元の提示）と即時性を重視
- Q&A: チャット形式UI。回答には参照元資料（ファイル/箇所）がクリッカブルに添付される
- 科目・ファイル管理: 科目ごとにツリー形式で保存ファイルを表示。Chrome拡張機能が自動アップロード時に科目を指定する（Web版にアップロードUIなし）
- 質問支援: ユーザーが曖昧な質問を入力した場合、LLMが具体的な選択肢を提示する。選択肢提示では資料検索を実施せず、LLMの推論のみで応答する。ユーザーが選択肢を選ぶと、元の曖昧な質問をコンテキストとして通常の検索フローへ移行する
- サポート: 質問履歴（スレッド保存）、不具合申告/お問い合わせフォームの常設

### 認証・アクセス制御
- 認証はSSO（OAuth/OIDC）を用いる
- 対応IdP（入口）: Google / Meta / Microsoft / LINE
- ユーザーごとのアクセス制限を厳格に実施する（資料・生成結果・ログの分離）

### 共有（将来想定）
- 初期は個人利用のみ
- 将来的に「科目の資料セット」のみ共有する可能性がある（科目ごとに資料内容が共通であり、整理・最適化目的）
- 質問履歴や重要箇所マーク等の個人の学習履歴は共有しない（プライバシー観点）

### データ/DB
- DBはFirestoreではなく、GCPのPostgreSQLを使用する
- AlloyDB AIは使用せず、PostgreSQL拡張のpgvectorを使用する
- Vision Reasoning等で資料から抜き出した内容を、検索に使うためDBに保存することは必須
- 事前OCR（テキスト化）はAgentの検索補助を目的に必須

### 検索/Agent
- Agentic Searchで資料を探索できるようにしたい
- 全文検索のみで行くべきか、EmbeddingされたドキュメントDBも必要か比較検討したい
- PostgreSQLのpgvector/ベクトル型を使うべきか検討したい
- MCPサーバの考え方を参考にすべきか検討したい

### 実装体制（責務）
- Agent開発はPython（LangGraph）
- 認証、イベント管理、キューイング用の受付コンテナはGo
- 前処理はGo + Kafkaで、OCR/Markdown化/Embedding化をキューイングする

### ロードマップ由来の要求
- Phase 4（小テストHTML解析）で扱う問題文・選択肢・正誤等の内容は「その場の解析のみ（保存しない/短期）」とする

## 2. 戦略レベルでの回答（結論）
### 技術的に可能か
- 事前OCR/抽出で「検索できるテキスト」を作り、検索→参照提示→要点/計画生成、という形での学習支援は技術的に実現可能
- 一方で、検索精度/遅延/コストは資料の形式と量、OCR品質、索引方式に依存するため、計測前提で進める

### RAG（検索+生成）との関係
- 学習支援の中心は、外部コーパス（自分の資料）から根拠を取り出す必要があるため、検索（全文/ベクトル）を含むRAG的構成は本質的
- 「RAGを採用するか否か」より、
  - どの索引（全文/ベクトル/ハイブリッド）を採用するか
  - どの粒度（ドキュメント/章/段落）で保存・参照するか
  - どのように権限制御をかけるか
  が成否を左右する

### 全文検索 vs Embedding DB（pgvector）
- 基本方針: 全文検索を基盤にして開始し、必要に応じてpgvectorでセマンティック検索を併用する
- 理由:
  - OCR後のテキストが整うほど全文検索の価値が高い
  - 同義語や抽象質問ではベクトルが効く
  - 「LLMが内蔵するベクトル能力」だけでは、外部資料を高速に引く索引にはならない

### pgvectorを使うべきか
- 使う価値は高い（PostgreSQL内でベクトル検索を扱えるため）
- ただし、初期は科目ID等で絞り込み+全文検索で十分な可能性がある
- データ量増加や要件（SLO/精度）に応じて、
  - 厳密検索→近似索引（HNSW/IVFFlat）
  - 全文+ベクトルのハイブリッド
  を段階的に導入する

### MCPサーバを参考にすべきか
- 「エージェントがツールを安全に呼ぶ」ための境界設計は参考にすべき
- 採用（プロトコル準拠）自体は、外部エコシステム連携の必要性を見て判断する

### Go/Pythonの責務（再確認）
- Go: 認証/認可境界、イベント/キュー、前処理（OCR/抽出/Embedding/DB反映）
- Python: LangGraphエージェント（検索ツールを使って探索し、根拠提示と学習支援の生成を行う）

## 3. 未決事項（要確認）
- （将来）学内IdP連携の必要性（Google Workspace / Azure AD / 学内IdP など）をいつ判断するか
- ユーザー分離の単位（初期: 個人のみ／将来: 科目の資料セットのみ共有、学習履歴は共有しない）
- 取り込む資料の主形式（PDF中心か、画像/HTML/スライド比率）
- 「科目ID」の付与方法（手動/自動、LMSから取得可否）
- 検索の最終的なSLO（許容レイテンシ）

（ロードマップ由来の確認事項）:
（なし）
